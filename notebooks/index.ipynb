{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from pidinst_experiments.core import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with RDA PIDINST and PIDINST-SCHEMA\n",
    "\n",
    "> Some thinking using ChatGPT on what a Experiment Bill of Materials (EBoM) might look like as an analogy to Software Bill of Materials (SBoM) and how it might be used to support the RDA PIDINST and PIDINST-SCHEMA working groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository contains some simple experiments with the RDA PIDINST schema and the creation of a simple ontology based on it. The schema is available at [rdawg-pidinst](https://github.com/rdawg-pidinst/schema/blob/master/schema.rst). The ontology is available at [pidinst.ttl](./data/pidinst.ttl) as well as SHACL shapes at [pidinst-shapes.ttl](./data/pidinst-shapes.ttl). It contains a sample pidinst JSON schema extracted from the [ODIS Architecture GitHub Issue](https://github.com/iodepo/odis-arch/issues/68#issuecomment-1353075204) in the file [pidinst-schema.json](./data/pidinst-schema.json) and [pidinst-example.json](./data/pidinst-example.json) which is a sample instance of the schema. A data prototype is in the Sarowar Hossain [Github repository](https://github.com/shmishkat/DataPrototype). Analysis was done with ChatGPT GPT-4 with bing web plugin for Retrieval Augmented Generation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "- [devcontainers](https://code.visualstudio.com/docs/remote/containers) for VSCode\n",
    "- [kglab](https://github.com/DerwenAI/kglab) for graph manipulation using:\n",
    "    - [pyshacl](https://github.com/RDFLib/pySHACL) for SHACL validation\n",
    "    - [rdflib](https://github.com/RDFLib/rdflib) for RDF manipulation\n",
    "- [nbdev](https://nbdev.fast.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Use Case\n",
    "The owner of the instrument is the NSF facility MagLab (https://ror.org/03s53g630). Josiah Carberry’s (https://orcid.org/0000-0002-1825-0097) data acquisition info: \n",
    " \n",
    "The experimental data (spectra) are acquired by a spectrometer (#1 HRS750, #2 IsoPlane,  Teledyne Princeton Instruments). The spectrometers are (almost) fully automated and controlled via the LightField software (Teledyne Princeton Instruments). LightField automatically saves the acquired data and all experiment settings (spectrometer settings) in one file. \n",
    "https://www.princetoninstruments.com/products/software-family/lightfield\n",
    " \n",
    "LightField saves files in *.SPE format (whatever it means). \n",
    " \n",
    " \n",
    "DS’ file- / folder- name convention:\n",
    " \n",
    "Folder name:\n",
    "PI name_Experiment ID_Magnet system-Instrument_Start date\n",
    " \n",
    "      Josiah_Carberry_P19401-E011-DC_SCM3-HRS750_02-12-2023\n",
    "      Josiah_Carberry_none_B114-IsoPlane_02-12-2023\n",
    " \n",
    "File name:\n",
    "Type of the experiment: PL, Ra(man), Re(flectance), Tr(ansmittance)\n",
    "Sample short name: ****\n",
    "Magnetic field: ***T (or from to )\n",
    "Temperature: ***K\n",
    "Light source:  SC, 532nm, 785nm, …  - Power: ***mW or uW, or percentage\n",
    "Central frequency / wl/energy: ***cm-1, nm, eV\n",
    "Slit: value: *** um\n",
    "Acq.time: ***min or sec\n",
    "Objective NA: ***NA\n",
    "Other: gate voltage, pressure, …\n",
    "  \n",
    "PL_WSe2-MoSe2_00.0T_to_05.2T_ 10K_633nm-100uW_720nm_30um_2min_0.65NA.SPE\n",
    "Ra_CsPr_30T_7.2K_532nm-2mW_550cm-1_30um_3x2min_0.82NA.SPE\n",
    "Re_InSe_0T_5K_SC-20%_600meV_50um_5sec_ 0.65NA_Gate Sweep -10V to +20V.SPE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thematic references in sample data\n",
    "\n",
    "ChatGPT was used to do the thematic analysis of the sample data. [PIDINST JSON Chat](https://chat.openai.com/share/2e4ef2c4-23e8-4f14-aca5-96bb2d0346af) is the link to the chat.\n",
    "\n",
    "The sample data provided has the following semantic themes that potentially map to persistent identifiers:\n",
    "\n",
    "- Observation ([sosa:Observation](https://www.w3.org/TR/vocab-ssn/#SOSAObservation), [schema:Observation](https://schema.org/Observation))\n",
    "- Experiment (Activity)\n",
    "- Instrument (PIDINST, sosa, [handle.net registry](https://handle.net/))\n",
    "- Sample (RRID)\n",
    "- Agent (Person, Organization, Software)\n",
    "    - Person (ORCID)\n",
    "    - Organization (ROR)\n",
    "    - Software ([SBoM](https://spdx.dev/), [Codemeta](https://github.com/codemeta/codemeta) )\n",
    "- Location ([w3c locn](https://www.w3.org/ns/locn), [schema.org](https://schema.org/location))\n",
    "- Dataset (DOI)\n",
    "- Physical Parameters: There are various physical parameters involved in the experiments, such as type of experiment (PL, Ra, Re, Tr), sample name, magnetic field, temperature, light source, power, central frequency/wavelength/energy, slit value, acquisition time, objective numerical aperture (NA), and others like gate voltage, pressure. Ontology patterns representing these physical parameters, their units of measurement (T, K, nm, mW/uW/%, cm-1/nm/eV, um, min/sec, NA, V), and their roles in the experiment would be necessary.\n",
    "- Experimental Procedure: The narrative also implies a certain procedure or workflow that is followed in conducting the experiments and saving the data. This could be represented by an ontology pattern describing scientific procedures or workflows.\n",
    "\n",
    "Thematically, we have something that is defined as an [Affordance](https://w3c.github.io/wot-architecture/#sec-affordances) in terms of variables that we can measure (this is confusing LLM agents and potential instrument settings. We need a specification of these \"affordances\" in the PIDINST doc. This is separate from the the settings that were used in the \"Observation\" which is an instantiation of a particular set of affordances in a \"Activity\" that is an experiment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    subgraph \"Agent\"\n",
    "        P[Person] -. \"rdfs:subClassOf\" .-> A[Agent]\n",
    "        O[Organization] -. \"rdfs:subClassOf\" .-> A\n",
    "        S[Software] -. \"rdfs:subClassOf\" .-> A\n",
    "    end\n",
    "    subgraph \"Entity\"\n",
    "        I[Instrument] -. \"rdfs:subClassOf\" .-> E[Entity]\n",
    "        Sm[Sample] -. \"rdfs:subClassOf\" .-> E\n",
    "        D[Dataset] -. \"rdfs:subClassOf\" .-> E\n",
    "        PP[PhysicalParameters] -. \"rdfs:subClassOf\" .-> E\n",
    "    end\n",
    "    subgraph \"Activity\"\n",
    "        Ob[Observation] -. \"rdfs:subClassOf\" .-> Act[Activity]\n",
    "        Ex[Experiment] -. \"rdfs:subClassOf\" .-> Act\n",
    "    end\n",
    "    subgraph \"Plan\"\n",
    "        EP[ExperimentalProcedure] -. \"rdfs:subClassOf\" .-> Pl[Plan]\n",
    "    end\n",
    "\n",
    "    P -- \"prov:wasAssociatedWith\" --> Ob\n",
    "    Ob -- \"prov:wasPartOf\" --> Ex\n",
    "    I -- \"prov:used\" --> Ob\n",
    "    Sm -- \"prov:used\" --> Ob\n",
    "    D -- \"prov:wasGeneratedBy\" --> Ob\n",
    "    O -- \"prov:actedOnBehalfOf\" --> P\n",
    "    S -- \"prov:actedOnBehalfOf\" --> I\n",
    "    L[Location] -- \"prov:atLocation\" --> Ob\n",
    "    L -- \"prov:atLocation\" --> I\n",
    "    L -- \"prov:atLocation\" --> Sm\n",
    "    PP -- \"prov:used\" --> Ob\n",
    "    EP -- \"prov:wasUsedBy\" --> Ex\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The narrative describes a complex experimental setup involving various physical parameters, instruments, and naming conventions. Here are the key themes or components present in the narrative, along with corresponding ontology patterns that might be necessary to describe them:\n",
    "\n",
    "1. **Instruments**: Spectrometers (#1 HRS750, #2 IsoPlane, Teledyne Princeton Instruments) and the controlling software (LightField software). This would require an ontology pattern that describes scientific instruments, their models, manufacturers, and associated software.\n",
    "\n",
    "2. **Experimental Data**: The acquired data and experiment settings saved in a `.spe` file. An ontology pattern representing data objects, their formats (`.spe`), and the parameters/settings they contain would be necessary.\n",
    "\n",
    "3. **File and Directory Naming Conventions**: The narrative describes a detailed naming convention for both directories and files. This could be represented using an ontology pattern that encapsulates the structure and semantics of these naming conventions.\n",
    "\n",
    "4. **Physical Parameters**: There are various physical parameters involved in the experiments, such as type of experiment (PL, Ra, Re, Tr), sample name, magnetic field, temperature, light source, power, central frequency/wavelength/energy, slit value, acquisition time, objective numerical aperture (NA), and others like gate voltage, pressure. Ontology patterns representing these physical parameters, their units of measurement (T, K, nm, mW/uW/%, cm-1/nm/eV, um, min/sec, NA, V), and their roles in the experiment would be necessary.\n",
    "\n",
    "5. **Experimental Procedure**: The narrative also implies a certain procedure or workflow that is followed in conducting the experiments and saving the data. This could be represented by an ontology pattern describing scientific procedures or workflows.\n",
    "\n",
    "6. **Samples**: Different samples are used in the experiments, as seen in the file naming convention. An ontology pattern representing scientific samples, their types, and characteristics would be needed.\n",
    "\n",
    "Remember, the role of an ontology is to provide a common framework for representing knowledge. Depending on the complexity and specific requirements of your use case, you might use existing ontologies (like the OBO Foundry ontologies), or develop custom ontologies tailored to your needs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [NSF Open Knowledge Network Roadmap](https://nsf-gov-resources.nsf.gov/2022-09/OKN%20Roadmap%20-%20Report_v03.pdf?VersionId=xmU9ccfd_nWRlDDSUE9HrOCvbM1fny24)\n",
    "- [RDA Instrument Identifiers](https://pidinst.org)\n",
    "\t- [rdawg-pidinst/schema: RDA WG PIDINST Metadata Schema (github.com)](https://github.com/rdawg-pidinst/schema)\n",
    "\t- [# Metadata Schema for the Persistent Identification of Instruments](https://zenodo.org/record/6396467#.ZFOkCIrMKcJ)\n",
    "- [Data Prototype](https://docs.google.com/document/d/1RRKxzwOW2SMn2bRAESBvnf7MmAmYy4itTrxaCFQrSOM/edit#heading=h.x8a40zxbykh3)\n",
    "- [12. Linking instrument PIDs to datasets — PIDINST 1.0b2.dev32+g510a615 documentation](https://docs.pidinst.org/en/latest/white-paper/linking-datasets.html)\n",
    "- [rdawg-pidinst/usage (github.com)](https://github.com/rdawg-pidinst/usage)\n",
    "- [schema/schema.rst at master · rdawg-pidinst/schema · GitHub](https://github.com/rdawg-pidinst/schema/blob/master/schema.rst)\n",
    "- [Persistent Identification of Instruments - Data Science Journal (codata.org)](https://datascience.codata.org/articles/10.5334/dsj-2020-018)\n",
    "- [RDA Physical Samples and Collections](https://www.rd-alliance.org/groups/physical-samples-and-collections-research-data-ecosystem-ig)\n",
    "\t- [ESIP and RDA Joint Webinar](https://www.rd-alliance.org/physical-sample-webinar1-June2021)\n",
    "\t- [Supporting Reproducibility by Capturing Physical Sample Data and Metadata in a Connected Electronic Lab Notebook](https://www.rd-alliance.org/sites/default/files/RDA%20%26%20ESIP%20Physical%20Samples%20Webinar%20June%202021.pdf)\n",
    "\t- [RRIDs: A Way to Track Samples Through the Scientific Literature](https://www.rd-alliance.org/PS_RRIDs_August2021_webinar)\n",
    "- [RDA iAdopt ](https://www.rd-alliance.org/group/interoperable-descriptions-observable-property-terminology-wg-i-adopt-wg/wiki/i-adopt)\n",
    "\t- [RDA iAdopt Github](https://github.com/i-adopt)\n",
    "\t- [RDA iAdopt Github - Ontology](https://github.com/i-adopt/ontology)\n",
    "\n",
    "##  Development of the [Ocean Data and Information System (ODIS)](https://github.com/iodepo/odis-arch) architecture\n",
    "- [International Oceanographic Data and Information Exchange](https://www.iode.org/)\n",
    "- [PIDInst JSON Schema](https://github.com/iodepo/odis-arch/issues/68#issuecomment-1353075204)\n",
    "- [EarthCube p418 JSON Schema to JSON-LD](https://github.com/earthcubearchitecture-project418/p418Docs/blob/master/publishing.md#developing-a-workflow-for-non-technical-authors)\n",
    "\n",
    "## Science on Schema.org\n",
    "- [Science on Schema.org](https://science-on-schema.org/)\n",
    "- [Experimental](https://github.com/ESIPFed/science-on-schema.org/blob/master/guides/Experimental.md)\n",
    "- [DataSet](https://github.com/ESIPFed/science-on-schema.org/blob/master/guides/Dataset.md)\n",
    "\n",
    "## Schema.org IoT\n",
    "- [IoT and Schema.org: Getting Started](https://schema.org/docs/iot-gettingstarted.html)\n",
    "\n",
    "## BioSchemas\n",
    "- [BioSchemas](https://bioschemas.org/)\n",
    "- [BioSchemas Github](https://github.com/BioSchemas/specifications)\n",
    "- [BioSchemas Github LabProtocol](https://github.com/BioSchemas/specifications/tree/master/LabProtocol)\n",
    "- [BioSchemas LabProtocol](https://bioschemas.org/profiles/LabProtocol/0.7-DRAFT)\n",
    "\n",
    "## Other Ontologies\n",
    "- [Sosa](https://www.w3.org/TR/vocab-ssn/)\n",
    "- [schema.org](https://schema.org/)\n",
    "- [schema.org/Product](https://schema.org/Product)\n",
    "- [W3C DCAT](https://www.w3.org/TR/vocab-dcat-3/)\n",
    "- [W3C Prov-o](https://www.w3.org/TR/prov-o/)\n",
    "- [W3C locn](https://www.w3.org/ns/locn)\n",
    "- [W3C Time Ontology](https://www.w3.org/TR/owl-time/)\n",
    "- [scientific instrument](https://www.wikidata.org/wiki/Q3099911)\n",
    "- [RoR](https://ror.org/)\n",
    "- [MagLab RoR](https://ror.org/03s53g630)\n",
    "- [ORCID](https://orcid.org/)\n",
    "- [Josiah Carberry - Fictional Orcid](https://orcid.org/0000-0002-1825-0097)\n",
    "- [SPDX](https://spdx.org/)\n",
    "- [SPDX License List](https://spdx.org/licenses/)\n",
    "- [SPDX Model Version 3 Github](https://github.com/spdx/spdx-3-model)\n",
    "- [Quantities, Units, Dimensions and Time](https://www.qudt.org/)\n",
    "- [SBoMs](https://www.ntia.gov/sbom)\n",
    "- [CyberSecurity and SBoMs](https://www.cisa.gov/sbom)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor Use case Narrative\n",
    "\n",
    "> The experimental data (spectra) are acquired by a spectrometer (#1 HRS750, #2 IsoPlane,  Teledyne Princeton Instruments). The spectrometers are (almost) fully automated and controlled via the LightField software (Teledyne Princeton Instruments). LightField automatically saves the acquired data and all experiment settings (spectrometer settings) in one file (spe file format). Each experiment is saved in a folder with the following directory naming convention: \"PI name_Experiment ID_Magnet system-Instrument_Start date\". Inside the folder is stored the spe file with the following file naming convention:\n",
    "\n",
    "> Type of the experiment: PL, Ra(man), Re(flectance), Tr(ansmittance):\n",
    "    - Sample short name: ****\n",
    "    - Magnetic field: ***T (or from to )\n",
    "    - Temperature: ***K\n",
    "    - Light source:  SC, 532nm, 785nm, …  - Power: ***mW or uW, or percentage\n",
    "    - Central frequency / wl/energy: ***cm-1, nm, eV\n",
    "    - Slit: value: *** um\n",
    "    - Acq.time: ***min or sec\n",
    "    - Objective NA: ***NA\n",
    "    - Other: gate voltage, pressure, …\n",
    "\n",
    "> For example: \n",
    "    PL_WSe2-MoSe2_00.0T_to_05.2T_ 10K_633nm-100uW_720nm_30um_2min_0.65NA.SPE\n",
    "    Ra_CsPr_30T_7.2K_532nm-2mW_550cm-1_30um_3x2min_0.82NA.SPE\n",
    "    Re_InSe_0T_5K_SC-20%_600meV_50um_5sec_ 0.65NA_Gate Sweep -10V to +20V.SPE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs\n",
    "\n",
    "- Use Keywords and descriptions for parameters\n",
    "- Model the instrument as a product\n",
    "- Model the settings more formally."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT summary\n",
    "Certainly, the following provides a range of options that the MagLab could consider when developing their semantic infrastructure, taking into consideration both minimal and more comprehensive approaches.\n",
    "\n",
    "1. **Minimal Approach - Schema.org metadata for experiments:**\n",
    "   - *Description:* Use Schema.org terms to describe the key features of your experiments. This involves adding appropriate Schema.org types (like `Dataset`, `Person`, `Organization`, etc.) and properties to your HTML metadata. \n",
    "   - *FAIR perspective:* This approach would increase the Findability and Interoperability of your datasets, as Schema.org is widely recognized and used by major search engines, aiding in data discovery. However, this is a general-purpose vocabulary and may lack the specificity required to fully describe scientific experiments.\n",
    "   \n",
    "2. **Mid-level Approach - Schema.org + ESIP Science-on-Schema.org guidelines:**\n",
    "   - *Description:* Extend the minimal approach by following ESIP's guidelines for using Schema.org in a scientific context. This provides a richer description of your data and includes terms from QUDT to quantify units and measuredVariables.\n",
    "   - *FAIR perspective:* By adhering to a community-accepted standard like ESIP, you enhance the Interoperability and Reusability of your data, as others in the scientific community will have a better understanding of the metadata and can use it more effectively.\n",
    "\n",
    "3. **Advanced Approach - Adopt a more descriptive Ontology Design Pattern (ODP):**\n",
    "   - *Description:* Implement a more formal ontology structure by creating a pattern that separates `Experiment`, `Instrument`, and `Sample` as distinct entities that participate in the `Experiment` process. This can be achieved with Semanticscience Integrated Ontology (SIO), which provides a rich semantic framework for describing scientific entities and processes. Here, `Instrument` and `Sample` participate in `Experiment`, which is a subclass of `SIO:Process` (or `prov:Activity` for alignment with PROV-O).\n",
    "   - *FAIR perspective:* This approach would greatly enhance the Interoperability and Reusability of your data by providing a robust and expressive semantic model for your experiments. This detailed semantic information can improve data discovery and understanding, aiding both human users and automated processes.\n",
    "\n",
    "4. **Comprehensive Approach - Integrate with existing ontologies and identifiers:**\n",
    "   - *Description:* Further expand the advanced approach by aligning with existing ontologies and identifier systems. This could include leveraging the PhysicalSamples ontology and Instrument identifiers (PIDINST) from RDA, BioSchemas recommendations, and RRIDs for tracking samples. Use OWL-Time and W3C locn for representing time and location, respectively.\n",
    "   - *FAIR perspective:* This approach ensures maximal Findability, Accessibility, Interoperability, and Reusability of your data by adhering to well-established standards and practices. It promotes data integration, comparison, and reuse across different studies and scientific fields.\n",
    "\n",
    "In summary, the chosen approach depends on the specific needs and resources of the MagLab. A more comprehensive approach offers greater FAIR compliance and utility for data users but requires more effort to implement and maintain. Consider the FAIR principles as guiding concepts, promoting maximum use and reuse of your valuable data. Remember that being FAIR is a journey, not a destination, and even small steps towards better metadata can have a significant impact on data utility."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "- We should probably use <https://w3id.org/pidinst/schema/> for namespace\n",
    "- Sanity check against [need \"platform\" / \"instrument\" / \"sensor\" field in top-level JSON-LD](https://github.com/iodepo/odis-arch/issues/68)\n",
    "- Sample PIDINST landing Page + Metadata\n",
    "- Guidance Document Instrument.md\n",
    "- PIDINST Schema dereference via w3id.org\n",
    "- ODP for \"experiment\" leveraging SIO and Prov-O\n",
    "- RO-Crate for experiment\n",
    "- HDF5 for experiment\n",
    "- Complete Wikidata for Princeton Instruments HRS750\n",
    "- Complete Wikidata for Princeton Instruments IsoPlane\n",
    "- Complete Wikidata for LightField\n",
    "- Prompt engineering for @context\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
